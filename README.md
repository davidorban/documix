**Documix**

Python License Status

**Documix** is a command-line tool that scrapes and packages website documentation into a single, AI-friendly text file, inspired by [Repomix](https://github.com/xai-org/repomix). Just as Repomix condenses code repositories for large language models (LLMs), Documix does the same for web-based docs—perfect for developers, researchers, and AI enthusiasts who want to analyze or process site content efficiently.

**Features**

* **Scrape & Package**: Fetch content from a documentation site (e.g., https://docs.windsurf.com/windsurf/) and bundle it into one .txt file.  
* **Structured Output**: Repomix-style format with headers, page paths, and content blocks for LLM compatibility.  
* **Customizable**: Skip irrelevant pages with .docignore or CLI flags.  
* **Metadata**: Optionally include page titles or metadata (e.g., Title: Introduction).  
* **Simple CLI**: Easy-to-use interface with minimal setup.

**Example Output**

\# Website: Windsurf Docs  
Generated by Documix on 2025-03-30  
Total pages processed: 3

\#\# Page: /windsurf/intro  
Title: Introduction to Windsurfing  
Welcome to windsurfing documentation...

\#\# Page: /windsurf/setup  
Title: Board Setup  
Setting up your windsurf board...

\#\# Page: /windsurf/techniques  
Title: Advanced Techniques  
Advanced techniques for windsurfing...

**Installation (MVP)**

1. **Clone the Repository**:  
2. bash

git clone https://github.com/davidorban/documix.git

3. cd documix  
4. **Install Dependencies**:  
5. bash  
6. pip install \-r requirements.txt  
7. *Note*: Requires Python 3.8+. See Dependencies (\#dependencies) for details.  
8. **Set Up Scraper**:  
   * Default: [Firecrawl](https://firecrawl.dev/). Sign up for an API key and set it as an environment variable:  
   * bash  
   * export FIRECRAWL\_API\_KEY="your-api-key"

*Future*: Install via PyPI with pip install documix (post-MVP).

**Usage**

**Basic Command**

Package a site into a single file:

bash

python documix.py package https://docs.windsurf.com/windsurf/

*Future*: documix package \<url\> (post-MVP).

Output: windsurf-docs-packaged.txt

**Options**

* \--output \<file\>: Custom output file (e.g., \--output mydocs.txt).  
* \--ignore \<patterns\>: Skip pages (e.g., \--ignore "login,search").  
* \--scraper \<tool\>: Choose scraper (e.g., \--scraper firecrawl).  
* \--metadata: Include page metadata (e.g., titles) in the output.

**With** .docignore

Create a .docignore file in the working directory to exclude pages:

login  
search

**Dependencies**

* firecrawl: Primary scraper (API key required).  
* requests: For HTTP checks.  
* Optional: scrapy, wget (future support).

**How It Works**

1. **Scrape**: Uses Firecrawl (or other tools) to fetch site content.  
2. **Process**: Aggregates pages, applies ignore patterns, and formats them with optional metadata.  
3. **Output**: Writes a single .txt file ready for LLMs.

**Why Documix?**

* Inspired by Repomix, but built for web documentation.  
* Simplifies feeding complex site content to AI models.  
* Open-source and extensible—contributions welcome\!

**Contributing**

We’d love your help\! Check out:

* CONTRIBUTING.md for guidelines.  
* Open issues for bugs or feature ideas.  
* Current focus: MVP (target release May 15, 2025).

**Quick Start for Contributors**

1. Fork and clone the repo.  
2. Install dev dependencies: pip install \-r requirements-dev.txt.  
3. Submit a PR with your changes\!

**Roadmap**

* MVP (Q2 2025): Core scraping, packaging, and metadata support.  
* Future: PDF extraction, GUI, LLM API integration.

**Legal Note**

Documix respects robots.txt and site terms. Use responsibly and check permissions before scraping.

**License**

MIT License (LICENSE) \- Free to use, modify, and distribute.

**Acknowledgments**

* Built with inspiration from [Repomix](https://github.com/xai-org/repomix).  
* Powered by the open-source community.

---

Questions? Open an issue or reach out\! Happy packaging\!
